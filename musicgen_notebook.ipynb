{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "collapsed": true,
        "id": "H0YVkG4kGAXL",
        "outputId": "b738eb79-718a-42fd-c435-1cf800028fc8"
      },
      "outputs": [],
      "source": [
        "!pip install pretty_midi\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import joblib\n",
        "import pretty_midi\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, LayerNormalization, Dropout, MultiHeadAttention, Flatten\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "# Google Drive'ı bağla\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWjsuqLquLh3"
      },
      "outputs": [],
      "source": [
        "# Enable mixed precision\n",
        "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Enable XLA JIT compilation for faster execution\n",
        "tf.config.optimizer.set_jit(True)\n",
        "\n",
        "# Enable GPU memory growth (avoid full pre-allocation)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwGRu6UZGKLl"
      },
      "outputs": [],
      "source": [
        "# Yollar\n",
        "MODEL_PATH = '/content/drive/MyDrive/transformer_music_model.keras'\n",
        "DURATION_SCALER_PATH = '/content/drive/MyDrive/duration_scaler.pkl'\n",
        "VELOCITY_SCALER_PATH = '/content/drive/MyDrive/velocity_scaler.pkl'\n",
        "INSTRUMENT_SCALER_PATH = '/content/drive/MyDrive/instrument_scaler.pkl'\n",
        "INSTRUMENT_ENCODER_PATH = '/content/drive/MyDrive/instrument_encoder.pkl'\n",
        "MIDI_DIR = '/content/drive/MyDrive/midi_files'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZshaXGfP5O3"
      },
      "outputs": [],
      "source": [
        "# 1. Veri hazırlama, model eğitimi ve kaydetme\n",
        "class MusicModel:\n",
        "\n",
        "    def __init__(self, seq_len=50, max_instr=4):\n",
        "        self.seq_len = seq_len\n",
        "        self.max_instr = max_instr\n",
        "        self.model = None\n",
        "        self.duration_scaler = MinMaxScaler()\n",
        "        self.velocity_scaler = MinMaxScaler()\n",
        "        self.instrument_scaler = MinMaxScaler()\n",
        "        self.instrument_encoder = LabelEncoder()\n",
        "\n",
        "    def extract_notes_by_time(self, midi_path, time_resolution=0.1):\n",
        "        midi = pretty_midi.PrettyMIDI(midi_path)\n",
        "        max_time = midi.get_end_time()\n",
        "        time_steps = np.arange(0, max_time, time_resolution)\n",
        "        note_groups = []  # ERROR:root:Internal Python error in the inspect module.\n",
        "\n",
        "    def train_and_save(self, midi_dir=MIDI_DIR):\n",
        "        files = [os.path.join(midi_dir, f) for f in os.listdir(midi_dir) if f.endswith('.mid')][:600]\n",
        "        all_groups = []\n",
        "        for f in files:\n",
        "            all_groups.extend(self.extract_notes_by_time(f))\n",
        "        data, instrs = [], []\n",
        "        for grp in all_groups:\n",
        "            row = [0] * (self.max_instr * 4)\n",
        "            for i, n in enumerate(grp[:self.max_instr]):\n",
        "                p, s, e, v, prog = n\n",
        "                dur = min(e - s, 2.0)\n",
        "                row[i*4:(i+1)*4] = [p, dur, v, prog]\n",
        "                instrs.append(prog)\n",
        "            data.append(row)\n",
        "        data = np.array(data)\n",
        "\n",
        "        # Scaler ve encoder\n",
        "        self.duration_scaler.fit(data[:, 1].reshape(-1, 1))\n",
        "        self.velocity_scaler.fit(data[:, 2].reshape(-1, 1))\n",
        "        self.instrument_scaler.fit(data[:, 3].reshape(-1, 1))\n",
        "        self.instrument_encoder.fit(instrs)  # ERROR:root:Internal Python error in the inspect module.\n",
        "\n",
        "        # Normalize\n",
        "        for i in range(self.max_instr):\n",
        "            data[:, i*4+1] = self.duration_scaler.transform(data[:, i*4+1].reshape(-1, 1)).flatten()\n",
        "            data[:, i*4+2] = self.velocity_scaler.transform(data[:, i*4+2].reshape(-1, 1)).flatten()\n",
        "            data[:, i*4+3] = self.instrument_scaler.transform(data[:, i*4+3].reshape(-1, 1)).flatten()\n",
        "\n",
        "        # Sequans oluştur\n",
        "        X, y = [], []\n",
        "        for idx in range(len(data) - self.seq_len):\n",
        "            X.append(data[idx:idx + self.seq_len])\n",
        "            y.append(data[idx + self.seq_len])\n",
        "        X, y = np.array(X), np.array(y)\n",
        "\n",
        "        # Modeli kur ve eğit\n",
        "        self.build_model(X.shape[-1])\n",
        "        self.model.fit(X, y, epochs=30, batch_size=64, validation_split=0.2)\n",
        "\n",
        "        # Kaydet\n",
        "        self.model.save(MODEL_PATH)\n",
        "        joblib.dump(self.duration_scaler, DURATION_SCALER_PATH)\n",
        "        joblib.dump(self.velocity_scaler, VELOCITY_SCALER_PATH)\n",
        "        joblib.dump(self.instrument_scaler, INSTRUMENT_SCALER_PATH)\n",
        "        joblib.dump(self.instrument_encoder, INSTRUMENT_ENCODER_PATH)\n",
        "        print('Eğitim tamamlandı ve model kaydedildi.')\n",
        "\n",
        "    def load(self):\n",
        "        self.model = load_model(MODEL_PATH)\n",
        "        self.duration_scaler = joblib.load(DURATION_SCALER_PATH)\n",
        "        self.velocity_scaler = joblib.load(VELOCITY_SCALER_PATH)\n",
        "        self.instrument_scaler = joblib.load(INSTRUMENT_SCALER_PATH)\n",
        "        self.instrument_encoder = joblib.load(INSTRUMENT_ENCODER_PATH)\n",
        "        print('Model ve scaler/encoder yüklendi.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XKndVWSP9eX"
      },
      "outputs": [],
      "source": [
        "# 2. MIDI -> WAV dönüşümü ve analiz\n",
        "\n",
        "def midi_to_wav(midi_path, wav_path, sf2_path='/usr/share/sounds/sf2/FluidR3_GM.sf2'):\n",
        "    temp = '/content/temp.wav'\n",
        "    subprocess.run(['fluidsynth', '-ni', sf2_path, midi_path, '-F', temp, '-r', '44100'], check=True)\n",
        "    sr, data = wavfile.read(temp)\n",
        "    wavfile.write(wav_path, sr, data)\n",
        "    os.remove(temp)\n",
        "    print(f'WAV dosyası oluşturuldu: {wav_path}')\n",
        "    return wav_path\n",
        "\n",
        "def analyze_midi(midi_path):\n",
        "    midi = pretty_midi.PrettyMIDI(midi_path)\n",
        "    notes = [n for inst in midi.instruments for n in inst.notes]\n",
        "    pitches = [n.pitch for n in notes]\n",
        "    durations = [n.end - n.start for n in notes]\n",
        "    info = {\n",
        "        'Total Notes': len(notes),\n",
        "        'Pitch Range': (min(pitches), max(pitches)) if pitches else (None, None),\n",
        "        'Avg Duration': float(np.mean(durations)) if durations else 0.0,\n",
        "        'Instruments': len(midi.instruments),\n",
        "        'Total Length': midi.get_end_time()\n",
        "    }\n",
        "    for k, v in info.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "    return info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtppG8DNQaWi"
      },
      "outputs": [],
      "source": [
        "# 3. Kullanıcı girdisi ve müzik üretimi\n",
        "\n",
        "def get_user_inputs():\n",
        "    print(\"Müzik üretim parametrelerini girin:\")\n",
        "    bpm = int(input('BPM (60-200): ') or 120)\n",
        "    duration = float(input('Süre (saniye): ') or 30)\n",
        "    rhythm = input(\"Ritim ('steady', 'syncopated', 'random'): \") or 'random'\n",
        "\n",
        "    # Enstrüman listesini göster\n",
        "    print(\"Kullanılabilir enstrümanlar ve program numaraları:\")\n",
        "    for i in range(128):\n",
        "        try:\n",
        "            print(f\"{i}: {pretty_midi.program_to_instrument_name(i)}\")\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    instr = input('Enstrüman program numaraları (örn. 0,24,40): ')\n",
        "    instruments = [int(i) for i in instr.split(',')]\n",
        "    return bpm, duration, rhythm, instruments\n",
        "\n",
        "def generate_music(model_obj, bpm, duration, rhythm, instruments, num_steps=300):\n",
        "    seed = np.random.rand(model_obj.seq_len, model_obj.max_instr * 4)\n",
        "    midi = pretty_midi.PrettyMIDI()\n",
        "    tracks = {p: pretty_midi.Instrument(program=p) for p in instruments}\n",
        "    t = 0\n",
        "    note_div = {'steady': 2, 'syncopated': 3}.get(rhythm, random.choice([2, 3, 4]))\n",
        "    step = 60 / bpm / note_div\n",
        "    last_pitch = -1\n",
        "\n",
        "    for _ in range(num_steps):\n",
        "        pred = model_obj.model.predict(seed[np.newaxis], verbose=0)[0]\n",
        "        pitch = int(np.clip(pred[0], 20, 127))\n",
        "\n",
        "        if pitch == last_pitch:\n",
        "            pitch += random.choice([-1, 1])\n",
        "        last_pitch = pitch\n",
        "\n",
        "        dur = max(0.1, model_obj.duration_scaler.inverse_transform([[pred[1]]])[0][0])\n",
        "        vel = int(np.clip(model_obj.velocity_scaler.inverse_transform([[pred[2]]])[0][0], 20, 127))\n",
        "        iv = model_obj.instrument_scaler.inverse_transform([[pred[3]]])[0][0]\n",
        "\n",
        "        pred_index = int(iv * len(model_obj.instrument_encoder.classes_))\n",
        "        pred_index = max(0, min(pred_index, len(model_obj.instrument_encoder.classes_) - 1))\n",
        "        instr_prog = model_obj.instrument_encoder.classes_[pred_index]\n",
        "\n",
        "        if instr_prog not in instruments:\n",
        "            instr_prog = random.choice(instruments)\n",
        "\n",
        "        note = pretty_midi.Note(velocity=vel, pitch=pitch, start=t, end=t + dur)\n",
        "        tracks[instr_prog].notes.append(note)\n",
        "        t += step\n",
        "        seed = np.vstack([seed[1:], pred])\n",
        "\n",
        "        if t >= duration:\n",
        "            break\n",
        "\n",
        "    for inst in tracks.values():\n",
        "        midi.instruments.append(inst)\n",
        "\n",
        "    out_midi = '/content/generated_music.mid'\n",
        "    midi.write(out_midi)\n",
        "    print(f'MIDI kaydedildi: {out_midi}')\n",
        "    return out_midi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AimgIcGoQF2m"
      },
      "outputs": [],
      "source": [
        "# Model eğitimi ve kaydetme\n",
        "mm = MusicModel()\n",
        "mm.train_and_save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11HP3ll8QaRz"
      },
      "outputs": [],
      "source": [
        "# Modeli yükleme\n",
        "mm = MusicModel()\n",
        "mm.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isv7TPVfQJ6a"
      },
      "outputs": [],
      "source": [
        "# Kullanıcıdan parametre al ve müzik üret\n",
        "bpm, duration, rhythm, instruments = get_user_inputs()\n",
        "midi_file = generate_music(mm, bpm, duration, rhythm, instruments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_53T3pHQMeM"
      },
      "outputs": [],
      "source": [
        "# Oluşan .mid dosyasını wava dönüştürme\n",
        "!apt update\n",
        "!apt install fluidsynth -y\n",
        "!pip install -q pretty_midi scipy\n",
        "\n",
        "import subprocess\n",
        "from scipy.io import wavfile\n",
        "\n",
        "midi_to_wav(midi_file, '/content/generated_music.wav')\n",
        "analyze_midi(midi_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Fd00Ehokf8Qh",
        "outputId": "9a73563a-952a-4a2e-9a12-1671636fe3d0"
      },
      "outputs": [],
      "source": [
        "# Çıktıyı analiz etme\n",
        "# Analyze the generated MIDI file and include BPM value\n",
        "if os.path.exists(midi_file):\n",
        "    print(f\"Analyzing MIDI file: {midi_file}\")\n",
        "    analyze_midi(midi_file)\n",
        "else:\n",
        "    print(f\"MIDI file not found at {midi_file}. Please ensure music is generated first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1BZSw66QQ9O"
      },
      "outputs": [],
      "source": [
        "# Çıktıyı analiz etme ve gerçek BPM ölçümü\n",
        "if os.path.exists(midi_file):\n",
        "    print(f\"Analyzing MIDI file: {midi_file}\")\n",
        "\n",
        "    # MIDI'den tempo tahmini\n",
        "    midi_obj = pretty_midi.PrettyMIDI(midi_file)\n",
        "    try:\n",
        "        est_tempo = midi_obj.estimate_tempo()\n",
        "        print(f\"Estimated MIDI Tempo: {est_tempo:.2f} BPM\")\n",
        "    except Exception as e:\n",
        "        print(f\"Tempo tahmin edilemedi: {e}\")\n",
        "\n",
        "    # Analiz bilgileri\n",
        "    analyze_midi(midi_file)\n",
        "else:\n",
        "    print(f\"MIDI file not found at {midi_file}. Please ensure music is generated first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j2XbKAdbQjJH",
        "outputId": "b3a5412e-cff8-470f-aaec-fd555b8e7138"
      },
      "outputs": [],
      "source": [
        "# Modelini yükleme\n",
        "\n",
        "model_path = '/content/drive/MyDrive/transformer_music_model.keras'\n",
        "\n",
        "# Check if the model file exists before attempting to load\n",
        "if os.path.exists(model_path):\n",
        "    print(f\"Loading model from {model_path}...\")\n",
        "    # Assuming your MusicModel class has a load method that handles this\n",
        "    # If not, you might need to explicitly use tf.keras.models.load_model\n",
        "    try:\n",
        "        mm = MusicModel() # Create an instance of your model class\n",
        "        mm.model = load_model(model_path) # Load the Keras model into the instance\n",
        "        print(\"Model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        # Handle the error appropriately, maybe try loading just the keras model\n",
        "        try:\n",
        "             model = load_model(model_path)\n",
        "             print(\"Loaded Keras model directly.\")\n",
        "             # If you loaded directly, you might need to manually load scalers/encoders\n",
        "             # depending on how your original code uses them.\n",
        "        except Exception as e2:\n",
        "            print(f\"Could not load Keras model directly either: {e2}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Model file not found at {model_path}\")\n",
        "    print(\"Please ensure the model file is in the specified Google Drive path.\")\n",
        "    print(\"Run the training section first if you haven't already.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
